library(nnet)
library(ggplot2)
library(caret)
library(tidyverse)
library(dplyr)
#데이터 전처리 과정
train_data <- read.csv("train_values.csv")
train_label <- read.csv("train_labels.csv")
train_data <- train_data[,c(2:39)]
train_label <- as.factor(train_label[,2])
str(train_data)
categ_idx <- c(8,9,10,11,12,13,14,26)
#onehot encoding
dmy <- dummyVars(~., data = train_data)
train_data <- data.frame(predict(dmy, newdata = train_data))
#dividing data
train_data <- scale(train_data, center = TRUE, scale = TRUE)
data <- data.frame(train_data, Class = train_label)
set.seed(123)
idx_train = sample(1:nrow(data), size = 150000)
data_trn = data[idx_train, ]
data = data[-idx_train,]
idx_valid = sample(1:nrow(data), size = 50000)
data_val=data[idx_valid,]
data_tst=data[-idx_valid,]
#Question 3
perf_eval_multi <- function(cm){
# Simple Accuracy
ACC = sum(diag(cm))/sum(cm)
# Balanced Correction Rate
BCR = 1
for (i in 1:dim(cm)[1]){
BCR = BCR*(cm[i,i]/sum(cm[i,]))
}
BCR = BCR^(1/dim(cm)[1])
return(c(ACC, BCR))
}
# Initialize performance matrix
perf_summary <- matrix(0, nrow = 2, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("ANN", "Multilogit")
#ANN------------------------------------------------------------------------
n_var <- dim(data)[2]
ANN_trn_input <- data_trn[,-n_var]
ANN_trn_target <- class.ind(data_trn[,n_var])
ANN_val_input <- data_val[,-n_var]
ANN_val_target <- class.ind(data_val[,n_var])
##Question 5##
#Combine training and validation dataset
input_idx <- c(1:68)
target_idx <- 69
nnet_trn <- rbind(data_trn,data_val)
nnet_input <- nnet_trn[,input_idx]
nnet_target <- class.ind(nnet_trn[,target_idx])
#Test the ANN
tst_input <- data_tst[,input_idx]
tst_target <- class.ind(data_tst[,target_idx])
val_perf_final <- matrix(0,10,2)
colnames(val_perf_final) <- c("ACC","BCR")
#question 6---------------------------------------------------
library(glmnet)
library(GA)
library(tidyverse)
library(corrplot)
library(moments)
library(ggplot2)
library(Epi)
library(dplyr)
perf_eval_multi <- function(cm){
# Simple Accuracy
ACC = sum(diag(cm))/sum(cm)
# Balanced Correction Rate
BCR = 1
for (i in 1:dim(cm)[1]){
BCR = BCR*(cm[i,i]/sum(cm[i,]))
}
BCR = BCR^(1/dim(cm)[1])
return(c(ACC, BCR))
}
# Initialize performance matrix
perf_summary <- matrix(0, nrow = 1, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("GA")
#8--------------------------------------------------------
input_idx <- c(1:68)
target_idx <- 69
nnet_trn <- rbind(data_trn,data_val)
nnet_input <- nnet_trn[,input_idx]
nnet_target <- as.factor(nnet_trn[,target_idx])
perf_eval_multi <- function(cm){
# Simple Accuracy
ACC = sum(diag(cm))/sum(cm)
# Balanced Correction Rate
BCR = 1
for (i in 1:dim(cm)[1]){
BCR = BCR*(cm[i,i]/sum(cm[i,]))
}
BCR = BCR^(1/dim(cm)[1])
return(c(ACC, BCR))
}
# Initialize performance matrix
perf_summary <- matrix(0, nrow = 3, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("non", "post", "pre")
library(tree)
#Pre-pruning
library(party)
library(ROCR)
min_criterion = c(0.9, 0.95, 0.99)
min_split = c(10, 30, 50, 100)
max_depth = c(0, 10, 5)
str(data_trn)
CART_pre_search_result = matrix(0,length(min_criterion)*length(min_split)*length(max_depth),11)
colnames(CART_pre_search_result) <- c("min_criterion", "min_split", "max_depth",
"TPR", "Precision", "TNR", "ACC", "BCR", "F1", "AUROC", "N_leaves")
input_idx <- c(1:68)
target_idx <- 69
nnet_input <- data_trn[,input_idx]
nnet_target <- class.ind(data_trn[,target_idx])
nnet_trn <- data.frame(nnet_input, nnet_target)
nnet_input <- data_val[,input_idx]
nnet_target <- class.ind(data_val[,target_idx])
nnet_val <- data.frame(nnet_input, nnet_target)
gc()
gc()
iter_cnt = 1
for (i in 1:length(min_criterion)){
for ( j in 1:length(min_split)){
for ( k in 1:length(max_depth)){
cat("CART Min criterion:", min_criterion[i], ", Min split:", min_split[j], ", Max depth:", max_depth[k], "\n")
tmp_control = ctree_control(mincriterion = min_criterion[i], minsplit = min_split[j], maxdepth = max_depth[k])
tmp_tree <- ctree(Class ~ ., data = data_trn, controls = tmp_control)
tmp_tree_val_prediction <- predict(tmp_tree, newdata = data_val)
tmp_tree_val_response <- treeresponse(tmp_tree, newdata = data_val)
tmp_tree_val_prob <- 1-unlist(tmp_tree_val_response, use.names=F)[seq(1,nrow(data_val)*2,2)]
tmp_tree_val_rocr <- prediction(tmp_tree_val_prob, data_val$Class)
# Confusion matrix for the validation dataset
tmp_tree_val_cm <- table(data_val$Class, tmp_tree_val_prediction)
# parameters
CART_pre_search_result[iter_cnt,1] = min_criterion[i]
CART_pre_search_result[iter_cnt,2] = min_split[j]
CART_pre_search_result[iter_cnt,3] = max_depth[k]
# Performances from the confusion matrix
CART_pre_search_result[iter_cnt,4:9] = perf_eval(tmp_tree_val_cm)
# AUROC
CART_pre_search_result[iter_cnt,10] = unlist(performance(tmp_tree_val_rocr, "auc")@y.values)
# Number of leaf nodes
CART_pre_search_result[iter_cnt,11] = length(nodes(tmp_tree, unique(where(tmp_tree))))
iter_cnt = iter_cnt + 1
}
}
}
nnet_input <- data_trn[,input_idx]
nnet_target <- (data_trn[,target_idx])
nnet_trn <- data.frame(nnet_input, nnet_target)
nnet_input <- data_val[,input_idx]
nnet_target <- (data_val[,target_idx])
nnet_val <- data.frame(nnet_input, nnet_target)
gc()
for (i in 1:length(min_criterion)){
for ( j in 1:length(min_split)){
for ( k in 1:length(max_depth)){
cat("CART Min criterion:", min_criterion[i], ", Min split:", min_split[j], ", Max depth:", max_depth[k], "\n")
tmp_control = ctree_control(mincriterion = min_criterion[i], minsplit = min_split[j], maxdepth = max_depth[k])
tmp_tree <- ctree(Class ~ ., data = data_trn, controls = tmp_control)
tmp_tree_val_prediction <- predict(tmp_tree, newdata = data_val)
tmp_tree_val_response <- treeresponse(tmp_tree, newdata = data_val)
tmp_tree_val_prob <- 1-unlist(tmp_tree_val_response, use.names=F)[seq(1,nrow(data_val)*2,2)]
#tmp_tree_val_rocr <- prediction(tmp_tree_val_prob, data_val$Class)
# Confusion matrix for the validation dataset
tmp_tree_val_cm <- table(data_val$Class, tmp_tree_val_prediction)
# parameters
CART_pre_search_result[iter_cnt,1] = min_criterion[i]
CART_pre_search_result[iter_cnt,2] = min_split[j]
CART_pre_search_result[iter_cnt,3] = max_depth[k]
# Performances from the confusion matrix
CART_pre_search_result[iter_cnt,4:9] = perf_eval(tmp_tree_val_cm)
# AUROC
#CART_pre_search_result[iter_cnt,10] = unlist(performance(tmp_tree_val_rocr, "auc")@y.values)
# Number of leaf nodes
#CART_pre_search_result[iter_cnt,11] = length(nodes(tmp_tree, unique(where(tmp_tree))))
iter_cnt = iter_cnt + 1
}
}
}
#memory.size(max = TRUE)
#memory.size(max = FALSE)
#memory.limit(size = NA)
#memory.limit(size = 50000)
perf_eval <- function(cm){
# True positive rate: TPR (Recall)
TPR <- cm[2,2]/sum(cm[2,])
# Precision
PRE <- cm[2,2]/sum(cm[,2])
# True negative rate: TNR
TNR <- cm[1,1]/sum(cm[1,])
# Simple Accuracy
ACC <- (cm[1,1]+cm[2,2])/sum(cm)
# Balanced Correction Rate
BCR <- sqrt(TPR*TNR)
# F1-Measure
F1 <- 2*TPR*PRE/(TPR+PRE)
return(c(TPR, PRE, TNR, ACC, BCR, F1))
}
# Performance table
Perf_Table <- matrix(0, nrow = 3, ncol = 6)
rownames(Perf_Table) <- c("Post-Pruning", "Pre-Pruning")
rownames(Perf_Table) <- c("non","Post-Pruning", "Pre-Pruning")
colnames(Perf_Table) <- c("TPR", "Precision", "TNR", "Accuracy", "BCR", "F1-Measure")
# Performance table
Perf_Table <- matrix(0, nrow = 1, ncol = 6)
rownames(Perf_Table) <- c( "Pre-Pruning")
colnames(Perf_Table) <- c("TPR", "Precision", "TNR", "Accuracy", "BCR", "F1-Measure")
Perf_Table
gc()
for (i in 1:length(min_criterion)){
for ( j in 1:length(min_split)){
for ( k in 1:length(max_depth)){
cat("CART Min criterion:", min_criterion[i], ", Min split:", min_split[j], ", Max depth:", max_depth[k], "\n")
tmp_control = ctree_control(mincriterion = min_criterion[i], minsplit = min_split[j], maxdepth = max_depth[k])
tmp_tree <- ctree(Class ~ ., data = data_trn, controls = tmp_control)
tmp_tree_val_prediction <- predict(tmp_tree, newdata = data_val)
tmp_tree_val_response <- treeresponse(tmp_tree, newdata = data_val)
tmp_tree_val_prob <- 1-unlist(tmp_tree_val_response, use.names=F)[seq(1,nrow(data_val)*2,2)]
#tmp_tree_val_rocr <- prediction(tmp_tree_val_prob, data_val$Class)
# Confusion matrix for the validation dataset
tmp_tree_val_cm <- table(data_val$Class, tmp_tree_val_prediction)
# parameters
CART_pre_search_result[iter_cnt,1] = min_criterion[i]
CART_pre_search_result[iter_cnt,2] = min_split[j]
CART_pre_search_result[iter_cnt,3] = max_depth[k]
# Performances from the confusion matrix
CART_pre_search_result[iter_cnt,4:9] = perf_eval(tmp_tree_val_cm)
# AUROC
#CART_pre_search_result[iter_cnt,10] = unlist(performance(tmp_tree_val_rocr, "auc")@y.values)
# Number of leaf nodes
#CART_pre_search_result[iter_cnt,11] = length(nodes(tmp_tree, unique(where(tmp_tree))))
iter_cnt = iter_cnt + 1
}
}
}
CART_pre_search_result <- CART_pre_search_result[order(CART_pre_search_result[,10], decreasing = T),]
CART_pre_search_result
CART_pre_search_result <- CART_pre_search_result[order(CART_pre_search_result[,7], decreasing = T),]
CART_pre_search_result
best_criterion <- CART_pre_search_result[1,1]
best_split <- CART_pre_search_result[1,2]
best_depth <- CART_pre_search_result[1,3]
tree_control = ctree_control(mincriterion = best_criterion, minsplit = best_split, maxdepth = best_depth)
CART_trn <- rbind(data_trn, data_val)
CART_pre <- ctree(Class ~ ., data = CART_trn, controls = tree_control)
CART_pre_prediction <- predict(CART_pre, newdata = data_tst)
CART_pre_response <- treeresponse(CART_pre, newdata = CART_tst)
CART_pre_response <- treeresponse(CART_pre, newdata = data_tst)
CART_pre_cm <- table(data_tst$Class, CART_pre_prediction)
CART_pre_cm
CART_pre_cm <- table(data_tst$Class, CART_pre_prediction)
CART_pre_cm
Perf_Table[2,] <- perf_eval(CART_pre_cm)
perf_summary <- matrix(0, nrow = 1, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("Decision Tree")
perf_summary[2,] <- perf_eval_multi(CART_pre_cm)
Perf_Table
Perf_Table[1,] <- perf_eval(CART_pre_cm)
Perf_Table
library(nnet)
library(ggplot2)
library(caret)
library(tidyverse)
library(dplyr)
#데이터 전처리 과정
train_data <- read.csv("train_values.csv")
train_label <- read.csv("train_labels.csv")
train_data <- train_data[,c(2:39)]
train_label <- as.factor(train_label[,2])
str(train_data)
categ_idx <- c(8,9,10,11,12,13,14,26)
#onehot encoding
dmy <- dummyVars(~., data = train_data)
train_data <- data.frame(predict(dmy, newdata = train_data))
#dividing data
train_data <- scale(train_data, center = TRUE, scale = TRUE)
data <- data.frame(train_data, Class = train_label)
set.seed(123)
idx_train = sample(1:nrow(data), size = 150000)
data_trn = data[idx_train, ]
data = data[-idx_train,]
idx_valid = sample(1:nrow(data), size = 50000)
data_val=data[idx_valid,]
data_tst=data[-idx_valid,]
#Question 3
perf_eval_multi <- function(cm){
# Simple Accuracy
ACC = sum(diag(cm))/sum(cm)
# Balanced Correction Rate
BCR = 1
for (i in 1:dim(cm)[1]){
BCR = BCR*(cm[i,i]/sum(cm[i,]))
}
BCR = BCR^(1/dim(cm)[1])
return(c(ACC, BCR))
}
# Initialize performance matrix
perf_summary <- matrix(0, nrow = 2, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("ANN", "Multilogit")
#ANN------------------------------------------------------------------------
n_var <- dim(data)[2]
ANN_trn_input <- data_trn[,-n_var]
ANN_trn_target <- class.ind(data_trn[,n_var])
ANN_val_input <- data_val[,-n_var]
ANN_val_target <- class.ind(data_val[,n_var])
#Question 9---------------------------------------------------------------------------------------------------
#Train multinomial logistic regression
nnet_trn <- rbind(data_trn,data_val)
nnet_input <- nnet_trn[,input_idx]
nnet_target <- class.ind(nnet_trn[,target_idx])
#Question 9---------------------------------------------------------------------------------------------------
#Train multinomial logistic regression
input_idx <- c(1:68)
target_idx <- 69
nnet_trn <- rbind(data_trn,data_val)
nnet_input <- nnet_trn[,input_idx]
nnet_target <- class.ind(nnet_trn[,target_idx])
ml_logit <- multinom(Class ~ ., data = nnet_trn)
t(summary(ml_logit)$coefficients)
ml_logit_pred <- predict(ml_logit, newdata = data_tst)
cfmatrix <- table(data_tst$Class,ml_logit_pred)
cfmatrix
perf_summary <- matrix(0, nrow = 1, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("Multi logit")
ml_logit_pred <- predict(ml_logit, newdata = data_tst)
cfmatrix <- table(data_tst$Class,ml_logit_pred)
cfmatrix
perf_summary <- matrix(0, nrow = 1, ncol = 2)
colnames(perf_summary) <- c("ACC", "BCR")
rownames(perf_summary) <- c("Multi logit")
perf_summary[1,] <- perf_eval_multi(cfmatrix)
perf_summary
